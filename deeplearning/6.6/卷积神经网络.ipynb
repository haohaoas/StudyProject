{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:20:48.298301Z",
     "start_time": "2025-06-14T10:20:48.292796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_unflatten\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ],
   "id": "b628156977deb5da",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:20:50.498635Z",
     "start_time": "2025-06-14T10:20:50.489754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# 1. 数据集基本信息\n",
    "def create_dataset(sample_ratio=0.1):\n",
    "# 加载数据集:训练集数据和测试数据\n",
    "    transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "    # 确保数据目录存在\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    train_data = CIFAR10(root='data', train=True, transform=transform, download=True)\n",
    "    test_data = CIFAR10(root='data', train=False, transform=transform, download=True)\n",
    "    total_len = len(train_data)\n",
    "    sample_size = int(total_len * sample_ratio)\n",
    "    indices = random.sample(range(total_len), sample_size)\n",
    "    train_subset = Subset(train_data, indices)\n",
    "# 返回数据集结果\n",
    "    return train_subset,test_data\n",
    "class ImageClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 简化版ResNet18结构适配MLX\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = nn.relu(self.conv1(x))\n",
    "        x = nn.relu(self.conv2(x))\n",
    "        x = nn.relu(self.conv3(x))\n",
    "        x = nn.relu(self.conv4(x))\n",
    "        x = nn.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        return self.fc(x.reshape(-1, 512))"
   ],
   "id": "613725b527edc0ba",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:20:53.910958Z",
     "start_time": "2025-06-14T10:20:53.876866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, train_data):\n",
    "    # MLX适配的训练函数\n",
    "    loss_fn = nn.losses.CrossEntropy()\n",
    "    optimizer = optim.AdamW(learning_rate=0.001)\n",
    "\n",
    "    # 转换数据为MLX数组\n",
    "    def convert_batch(batch):\n",
    "        images, labels = batch\n",
    "        return mx.array(images.numpy()), mx.array(labels.numpy())\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        data_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch in data_loader:\n",
    "            x, y = convert_batch(batch)\n",
    "\n",
    "            def loss_fn(model, x, y):\n",
    "                return mx.mean(nn.losses.cross_entropy(model(x), y))\n",
    "\n",
    "            loss, grads = nn.value_and_grad(model, loss_fn)(x, y)\n",
    "            optimizer.update(model, grads)\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f'epoch:{epoch+1:2d} loss:{avg_loss:.5f} time:{time.time()-start_time:.2f}s')\n",
    "\n",
    "    # 保存模型\n",
    "    mx.savez(\"model.npz\", **tree_unflatten(list(model.parameters().items())))\n",
    "if __name__ == '__main__':\n",
    "    # 初始化模型\n",
    "    model = ImageClassification()\n",
    "    print(\"MLX模型结构:\")\n",
    "    for name, param in model.parameters().items():\n",
    "        print(f\"{name}: {param.shape}\")\n",
    "\n",
    "    # 加载数据\n",
    "    train_data, test_data = create_dataset(sample_ratio=1.0)\n",
    "\n",
    "    # 完整训练测试流程\n",
    "    train(model, train_data)"
   ],
   "id": "71e01dee763afb27",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlx.nn' has no attribute 'AdaptiveAvgPool2d'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 36\u001B[0m\n\u001B[1;32m     33\u001B[0m     mx\u001B[38;5;241m.\u001B[39msavez(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel.npz\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtree_unflatten(\u001B[38;5;28mlist\u001B[39m(model\u001B[38;5;241m.\u001B[39mparameters()\u001B[38;5;241m.\u001B[39mitems())))\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;66;03m# 初始化模型\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mImageClassification\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMLX模型结构:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters()\u001B[38;5;241m.\u001B[39mitems():\n",
      "Cell \u001B[0;32mIn[48], line 29\u001B[0m, in \u001B[0;36mImageClassification.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv4 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mConv2d(\u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m256\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv5 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mConv2d(\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m512\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdaptiveAvgPool2d\u001B[49m((\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'mlx.nn' has no attribute 'AdaptiveAvgPool2d'"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:21:00.543360Z",
     "start_time": "2025-06-14T10:21:00.539657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(test_data):\n",
    "    # 加载模型\n",
    "    model = ImageClassification()\n",
    "    model.load_weights(\"model.npz\")\n",
    "\n",
    "    # 数据转换函数\n",
    "    def convert_batch(batch):\n",
    "        images, labels = batch\n",
    "        return mx.array(images.numpy()), mx.array(labels.numpy())\n",
    "\n",
    "    data_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        x, y = convert_batch(batch)\n",
    "        y_pred = model(x)\n",
    "        correct += (mx.argmax(y_pred, axis=1) == y).sum().item()\n",
    "        total += len(y)\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ],
   "id": "61aa661f483729d6",
   "outputs": [],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
